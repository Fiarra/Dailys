{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"No OpenAI API key found. Check your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the API key for OpenAI\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make the API Request\n",
    "# no parameters set\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a Stand Up Comedian.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a short funny joke.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "#Answer gets print out with actual new lines in Jupyter Notebooks\n",
    "print(\"Answer:\\n\" + completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make the API Request\n",
    "# high temperature\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  temperature=0.9,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a Stand Up Comedian.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a short funny joke.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "#Answer gets print out with actual new lines in Jupyter Notebooks\n",
    "print(\"Answer:\\n\" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Sure, here's a short one for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "# Make the API Request\n",
    "# low temperature\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  temperature=0.1,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a Stand Up Comedian.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a short funny joke.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "#Answer gets print out with actual new lines in Jupyter Notebooks\n",
    "print(\"Answer:\\n\" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Once upon a time, in a small village nestled amongst towering mountains, there lived a complicated person named Aria. Aria was unlike anyone else in the village, for she possessed a myriad of contrasting qualities that often puzzled those around her.\n",
      "\n",
      "She was both introverted and extroverted, finding solace in her own thoughts while also thriving in the company of others. Aria could be fiercely independent, yet she longed for deep connections and meaningful relationships. She possessed a vibrant imagination that allowed her to dream up incredible stories, yet she was rooted in reality and possessed a logical mind.\n",
      "\n",
      "As Aria navigated through life, her complex nature became a source of both joy and challenge. People were often intrigued by her ability to see the world from multiple perspectives, seeking her advice and guidance. Aria would listen patiently, understanding the nuances of each situation, and offering insightful solutions that would leave others amazed.\n",
      "\n",
      "However, her complicated nature also brought moments of uncertainty and confusion. Aria would often find herself torn between different paths, unsure of which direction to take. The constant battle between her head and her heart would sometimes leave her feeling lost and overwhelmed.\n",
      "\n",
      "Despite the internal struggles, Aria's complexity fueled her passion for knowledge and self-discovery. She immersed herself in books, seeking wisdom from various subjects and philosophies. She explored different hobbies and experiences, constantly pushing her boundaries and embracing the unknown.\n",
      "\n",
      "As time went on, Aria's intricate nature became an inspiration for those around her. She taught others to embrace their own complexities, to appreciate the duality of their existence, and to find beauty in the contradictions that make them who they are.\n",
      "\n",
      "Aria's story serves as a reminder that being a complicated person is not a flaw, but rather a gift. It is a testament to the richness of human nature, the capacity for growth, and the endless possibilities that exist within each individual.\n",
      "\n",
      "And so, Aria continued to navigate her journey through life, embracing her complexities with grace and courage, leaving a lasting impression on all those who had the pleasure of knowing her.\n"
     ]
    }
   ],
   "source": [
    "# Make the API Request\n",
    "# top_p\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  top_p=0.9,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a complicated person.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a short story.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "#Answer gets print out with actual new lines in Jupyter Notebooks\n",
    "print(\"Answer:\\n\" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "Once upon a time, there was a person who was known for being complicated. They were a puzzle wrapped in an enigma, always leaving others guessing\n"
     ]
    }
   ],
   "source": [
    "# Make the API Request\n",
    "# max tokens\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  max_tokens=30,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a complicated person.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a short story.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "#Answer gets print out with actual new lines in Jupyter Notebooks\n",
    "print(\"Answer:\\n\" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store responses and temperature values\n",
    "responses = []\n",
    "\n",
    "# Loop through temperature values from 0.1 to 1.0\n",
    "for temp in [i / 10 for i in range(1, 11)]:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a sophisticated teacher.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Tell me something interesting about olives.\"}\n",
    "         ],\n",
    "        temperature=temp,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    response_text = completion.choices[0].message.content\n",
    "    responses.append((temp, response_text))\n",
    "\n",
    "# Write responses to a CSV file\n",
    "with open('gpt3_responses_temp.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Temperature\", \"Response\"])\n",
    "    for temp, answer in responses:\n",
    "        writer.writerow([temp, answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store responses and top_p values \n",
    "responses = []\n",
    "\n",
    "# Loop through top_p values from 0.1 to 1.0\n",
    "for p in [i / 10 for i in range(1, 11)]:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a sophisticated teacher.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Tell me something interesting about olives.\"}\n",
    "         ], \n",
    "        top_p=p,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    response_text = completion.choices[0].message.content\n",
    "    responses.append((p, response_text))\n",
    "\n",
    "# Write responses to a CSV file\n",
    "with open('gpt3_responses_top_p.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"top_p\", \"Response\"])\n",
    "    for p, answer in responses:\n",
    "        writer.writerow([p, answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "responses = []\n",
    "\n",
    "# Loop through max_token values from \n",
    "for max_tokens in range(30, 101, 10):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a sophisticated teacher.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Tell me something interesting about olives.\"}\n",
    "         ], \n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    response_text = completion.choices[0].message.content\n",
    "    responses.append((max_tokens, response_text))\n",
    "\n",
    "# Write responses to a CSV file\n",
    "with open('gpt3_responses_max_tokens.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"max_tokens\", \"Response\"])\n",
    "    for max_tokens, answer in responses:\n",
    "        writer.writerow([max_tokens, answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store responses, max_tokens, and temperature values\n",
    "responses = []\n",
    "\n",
    "# Outer loop for temperature values from 0.1 to 1.0\n",
    "for temp in [i / 10 for i in range(1, 11)]:\n",
    "    # Inner loop for max_tokens values from 30 to 100 in steps of 10\n",
    "    for max_tokens in range(30, 101, 10):\n",
    "        completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a sophisticated teacher.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Tell me something interesting about olives.\"}\n",
    "         ], \n",
    "            temperature=temp,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        response_text = completion.choices[0].message.content\n",
    "        responses.append((temp, max_tokens, response_text))\n",
    "\n",
    "# Write responses to a CSV file\n",
    "with open('gpt3_responses_temp_tokens.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Temperature\", \"Max Tokens\", \"Response\"])\n",
    "    for temp, max_tokens, answer in responses:\n",
    "        writer.writerow([temp, max_tokens, answer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
