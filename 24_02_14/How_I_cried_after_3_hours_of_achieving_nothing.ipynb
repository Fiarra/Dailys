{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zantana/myenv/lib/python3.8/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import csv\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import instaloader\n",
    "from datetime import datetime\n",
    "from itertools import dropwhile, takewhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"No OpenAI API key found. Check your .env file.\")\n",
    "\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JSON Query to api/v1/media/3208186110936122731/comments/: HTTP error code 403. [retrying; skip with ^C]\n",
      "JSON Query to api/v1/media/3208186110936122731/comments/: HTTP error code 403. [retrying; skip with ^C]\n"
     ]
    },
    {
     "ename": "ConnectionException",
     "evalue": "JSON Query to api/v1/media/3208186110936122731/comments/: HTTP error code 403.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/instaloader/instaloadercontext.py:409\u001b[0m, in \u001b[0;36mInstaloaderContext.get_json\u001b[0;34m(self, path, params, host, session, _attempt, response_headers)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectionException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP error code \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(resp\u001b[38;5;241m.\u001b[39mstatus_code))\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mConnectionException\u001b[0m: HTTP error code 403.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/instaloader/instaloadercontext.py:409\u001b[0m, in \u001b[0;36mInstaloaderContext.get_json\u001b[0;34m(self, path, params, host, session, _attempt, response_headers)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectionException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP error code \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(resp\u001b[38;5;241m.\u001b[39mstatus_code))\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mConnectionException\u001b[0m: HTTP error code 403.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/instaloader/instaloadercontext.py:409\u001b[0m, in \u001b[0;36mInstaloaderContext.get_json\u001b[0;34m(self, path, params, host, session, _attempt, response_headers)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectionException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP error code \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(resp\u001b[38;5;241m.\u001b[39mstatus_code))\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mConnectionException\u001b[0m: HTTP error code 403.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectionException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 79\u001b[0m\n\u001b[1;32m     74\u001b[0m  \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_users_posts_with_periods(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzuckerjagdwurst\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m  \u001b[38;5;66;03m#cls.download_hastag_posts(\"zuckerjagdwurst\")\u001b[39;00m\n\u001b[1;32m     76\u001b[0m  \u001b[38;5;66;03m# cls.get_users_followers(\"zuckerjagdwurst\")\u001b[39;00m\n\u001b[1;32m     77\u001b[0m  \u001b[38;5;66;03m# cls.get_users_followings(\"zuckerjagdwurst\")\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#cls.get_post_comments(\"zuckerjagdwurst\")\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m  \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_post_info_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzuckerjagdwurst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 67\u001b[0m, in \u001b[0;36mGetInstagramProfile.get_post_info_csv\u001b[0;34m(self, username)\u001b[0m\n\u001b[1;32m     64\u001b[0m posturl \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.instagram.com/p/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mpost\u001b[38;5;241m.\u001b[39mshortcode\n\u001b[1;32m     65\u001b[0m writer\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, post\u001b[38;5;241m.\u001b[39mmediaid, post\u001b[38;5;241m.\u001b[39mprofile, post\u001b[38;5;241m.\u001b[39mcaption, post\u001b[38;5;241m.\u001b[39mdate, post\u001b[38;5;241m.\u001b[39mlocation, posturl, post\u001b[38;5;241m.\u001b[39mtypename, post\u001b[38;5;241m.\u001b[39mmediacount, post\u001b[38;5;241m.\u001b[39mcaption_hashtags, post\u001b[38;5;241m.\u001b[39mcaption_mentions, post\u001b[38;5;241m.\u001b[39mtagged_users, post\u001b[38;5;241m.\u001b[39mlikes, post\u001b[38;5;241m.\u001b[39mcomments, post\u001b[38;5;241m.\u001b[39mtitle, post\u001b[38;5;241m.\u001b[39murl])\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_comments\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     68\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m\"\u001b[39m, comment\u001b[38;5;241m.\u001b[39mid, comment\u001b[38;5;241m.\u001b[39mowner\u001b[38;5;241m.\u001b[39musername, comment\u001b[38;5;241m.\u001b[39mtext, comment\u001b[38;5;241m.\u001b[39mcreated_at_utc])\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/instaloader/structures.py:666\u001b[0m, in \u001b[0;36mPost.get_comments\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_postcomment(comment[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m comment_edges]\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomments \u001b[38;5;241m>\u001b[39m NodeIterator\u001b[38;5;241m.\u001b[39mpage_length():\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;66;03m# comments pagination via our graphql query does not work reliably anymore (issue #2125), fallback to an\u001b[39;00m\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;66;03m# iphone endpoint if needed.\u001b[39;00m\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_comments_via_iphone_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m NodeIterator(\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context,\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m97b41c52301f77ce508f55e66d17620e\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.instagram.com/p/\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcode),\n\u001b[1;32m    675\u001b[0m )\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/instaloader/structures.py:609\u001b[0m, in \u001b[0;36mPost._get_comments_via_iphone_endpoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m next_min_id:\n\u001b[1;32m    607\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m _paginated_comments(_query(next_min_id))\n\u001b[0;32m--> 609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _paginated_comments(\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/instaloader/structures.py:557\u001b[0m, in \u001b[0;36mPost._get_comments_via_iphone_endpoint.<locals>._query\u001b[0;34m(min_id)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_query\u001b[39m(min_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    556\u001b[0m     pagination_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: min_id} \u001b[38;5;28;01mif\u001b[39;00m min_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_iphone_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapi/v1/media/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmediaid\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/comments/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcan_support_threading\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpermalink_enabled\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfalse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpagination_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/instaloader/instaloadercontext.py:567\u001b[0m, in \u001b[0;36mInstaloaderContext.get_iphone_json\u001b[0;34m(self, path, params)\u001b[0m\n\u001b[1;32m    564\u001b[0m     tempsession\u001b[38;5;241m.\u001b[39mcookies\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    566\u001b[0m response_headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()    \u001b[38;5;66;03m# type: Dict[str, Any]\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mi.instagram.com\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtempsession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# Extract the ig-set-* headers and use them in the next request\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m response_headers\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/instaloader/instaloadercontext.py:435\u001b[0m, in \u001b[0;36mInstaloaderContext.get_json\u001b[0;34m(self, path, params, host, session, _attempt, response_headers)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_other_query:\n\u001b[1;32m    434\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rate_controller\u001b[38;5;241m.\u001b[39mhandle_429(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_attempt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attempt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[skipped by user]\u001b[39m\u001b[38;5;124m\"\u001b[39m, repeat_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/instaloader/instaloadercontext.py:435\u001b[0m, in \u001b[0;36mInstaloaderContext.get_json\u001b[0;34m(self, path, params, host, session, _attempt, response_headers)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_other_query:\n\u001b[1;32m    434\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rate_controller\u001b[38;5;241m.\u001b[39mhandle_429(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_attempt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attempt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[skipped by user]\u001b[39m\u001b[38;5;124m\"\u001b[39m, repeat_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/instaloader/instaloadercontext.py:425\u001b[0m, in \u001b[0;36mInstaloaderContext.get_json\u001b[0;34m(self, path, params, host, session, _attempt, response_headers)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m QueryReturnedNotFoundException(error_string) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 425\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionException(error_string) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror(error_string \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [retrying; skip with ^C]\u001b[39m\u001b[38;5;124m\"\u001b[39m, repeat_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mConnectionException\u001b[0m: JSON Query to api/v1/media/3208186110936122731/comments/: HTTP error code 403."
     ]
    }
   ],
   "source": [
    "#Instagram always stops the script after downloading the Profile pic.\n",
    "class GetInstagramProfile():\n",
    "    def __init__(self) -> None:\n",
    "        # Initializes the Instaloader object for downloading data from Instagram.\n",
    "        self.L = instaloader.Instaloader()\n",
    "\n",
    "    def download_users_profile_picture(self, username):\n",
    "        # Downloads the profile picture of the specified username.\n",
    "        self.L.download_profile(username, profile_pic_only=True)\n",
    "\n",
    "    def download_users_posts_with_periods(self, username):\n",
    "        # Downloads posts of a user within a specific date range.\n",
    "        posts = instaloader.Profile.from_username(self.L.context, username).get_posts()\n",
    "        SINCE = datetime(2034, 2, 1)  # Start date\n",
    "        UNTIL = datetime(2024, 2, 14)  # End date\n",
    "\n",
    "        # Filters posts within the specified date range and downloads them.\n",
    "        for post in takewhile(lambda p: p.date > SINCE, dropwhile(lambda p: p.date > UNTIL, posts)):\n",
    "            self.L.download_post(post, username)\n",
    "\n",
    "    def download_hastag_posts(self, hashtag):\n",
    "        # Downloads posts associated with a specific hashtag.\n",
    "        for post in instaloader.Hashtag.from_name(self.L.context, hashtag).get_posts():\n",
    "            self.L.download_post(post, target='#'+hashtag)\n",
    "\n",
    "    def get_users_followers(self, user_name):\n",
    "        '''Note: login required to get a profile's followers.'''\n",
    "        # Prompts the user to login for accessing follower data.\n",
    "        self.L.login(input(\"testitest_97\"), input(\"datasciencerocks\"))\n",
    "        profile = instaloader.Profile.from_username(self.L.context, user_name)\n",
    "        file = open(\"follower_names.txt\", \"a+\")\n",
    "        for followee in profile.get_followers():\n",
    "            username = followee.username\n",
    "            file.write(username + \"\\n\")\n",
    "            print(username)\n",
    "\n",
    "    def get_users_followings(self, user_name):\n",
    "        '''Note: login required to get a profile's followings.'''\n",
    "        # Similar to get_users_followers, but for retrieving who a user is following.\n",
    "        self.L.login(input(\"testitest_97\"), input(\"datasciencerocks\"))\n",
    "        profile = instaloader.Profile.from_username(self.L.context, user_name)\n",
    "        file = open(\"following_names.txt\", \"a+\")\n",
    "        for followee in profile.get_followees():\n",
    "            username = followee.username\n",
    "            file.write(username + \"\\n\")\n",
    "            print(username)\n",
    "\n",
    "    def get_post_comments(self, username):\n",
    "        # Retrieves and prints comments for each post of a specified user.\n",
    "        posts = instaloader.Profile.from_username(self.L.context, username).get_posts()\n",
    "        for post in posts:\n",
    "            for comment in post.get_comments():\n",
    "                print(\"comment.id  : \"+str(comment.id))\n",
    "                print(\"comment.owner.username  : \"+comment.owner.username)\n",
    "                print(\"comment.text  : \"+comment.text)\n",
    "                print(\"comment.created_at_utc  : \"+str(comment.created_at_utc))\n",
    "                print(\"************************************************\")\n",
    "\n",
    "    def get_post_info_csv(self, username):\n",
    "        # Extracts detailed information about each post from a specified user and saves it into a CSV file.\n",
    "        with open(username+'.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            posts = instaloader.Profile.from_username(self.L.context, username).get_posts()\n",
    "            for post in posts:\n",
    "                posturl = \"https://www.instagram.com/p/\"+post.shortcode\n",
    "                writer.writerow([\"post\", post.mediaid, post.profile, post.caption, post.date, post.location, posturl, post.typename, post.mediacount, post.caption_hashtags, post.caption_mentions, post.tagged_users, post.likes, post.comments, post.title, post.url])\n",
    "                \n",
    "                for comment in post.get_comments():\n",
    "                    writer.writerow([\"comment\", comment.id, comment.owner.username, comment.text, comment.created_at_utc])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cls = GetInstagramProfile()\n",
    "    # Uncomment the method you want to run. Make sure to provide the correct usernames or hashtags.\n",
    "    #cls.download_users_profile_picture(\"zuckerjagdwurst\")\n",
    "    cls.download_users_posts_with_periods(\"zuckerjagdwurst\")\n",
    "    #cls.download_hastag_posts(\"zuckerjagdwurst\")\n",
    "    # cls.get_users_followers(\"zuckerjagdwurst\")\n",
    "    # cls.get_users_followings(\"zuckerjagdwurst\")\n",
    "   #cls.get_post_comments(\"zuckerjagdwurst\")\n",
    "    cls.get_post_info_csv(\"zuckerjagdwurst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'desired_capabilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m service \u001b[38;5;241m=\u001b[39m Service(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath/to/chromedriver\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m capabilities \u001b[38;5;241m=\u001b[39m DesiredCapabilities\u001b[38;5;241m.\u001b[39mCHROME\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 9\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_capabilities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapabilities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath/to/chromedriver\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Go to the Instagram post URL\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'desired_capabilities'"
     ]
    }
   ],
   "source": [
    "#also not working\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "import time\n",
    " \n",
    "# Launch the Chrome browser\n",
    "service = Service('path/to/chromedriver')\n",
    "capabilities = DesiredCapabilities.CHROME.copy()\n",
    "driver = webdriver.Chrome(service=service, desired_capabilities=capabilities)\n",
    "driver = webdriver.Chrome('path/to/chromedriver')\n",
    " \n",
    "# Go to the Instagram post URL\n",
    "post_url = 'https://www.instagram.com/p/<post_id>/'\n",
    "driver.get(post_url)\n",
    " \n",
    "# Log in to Instagram\n",
    "username = 'your_username'\n",
    "password = 'your_password'\n",
    "username_field = driver.find_element_by_name('username')\n",
    "password_field = driver.find_element_by_name('password')\n",
    "username_field.send_keys(username)\n",
    "password_field.send_keys(password)\n",
    "password_field.submit()\n",
    "import time\n",
    "# Wait for the page to load\n",
    "time.sleep(5)\n",
    "# Get the comments\n",
    "comments = []\n",
    "comment_divs = driver.find_elements_by_xpath('//div[@class=\"C4VMK\"]/span')\n",
    "for comment_div in comment_divs:    \n",
    "    comments.append(comment_div.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuck it we go for amazon reviews now B01N1O0F2K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in /Users/Zantana/myenv/lib/python3.8/site-packages (2.11.0)\n",
      "Requirement already satisfied: Twisted<23.8.0,>=18.9.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (22.10.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (42.0.2)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (1.2.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (1.8.1)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (24.0.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (1.6.2)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (24.1.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (2.1.2)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (6.1)\n",
      "Requirement already satisfied: protego>=0.1.15 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (0.3.0)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (0.8.0)\n",
      "Requirement already satisfied: setuptools in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (49.2.1)\n",
      "Requirement already satisfied: packaging in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (23.2)\n",
      "Requirement already satisfied: tldextract in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (5.1.1)\n",
      "Requirement already satisfied: lxml>=4.4.1 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (5.1.0)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy) (2.0.7)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/Zantana/myenv/lib/python3.8/site-packages (from cryptography>=36.0.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in /Users/Zantana/myenv/lib/python3.8/site-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from service-identity>=18.1.0->scrapy) (23.2.0)\n",
      "Requirement already satisfied: pyasn1 in /Users/Zantana/myenv/lib/python3.8/site-packages (from service-identity>=18.1.0->scrapy) (0.5.1)\n",
      "Requirement already satisfied: pyasn1-modules in /Users/Zantana/myenv/lib/python3.8/site-packages (from service-identity>=18.1.0->scrapy) (0.3.0)\n",
      "Requirement already satisfied: constantly>=15.1 in /Users/Zantana/myenv/lib/python3.8/site-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (23.10.4)\n",
      "Requirement already satisfied: incremental>=21.3.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /Users/Zantana/myenv/lib/python3.8/site-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /Users/Zantana/myenv/lib/python3.8/site-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (4.9.0)\n",
      "Requirement already satisfied: idna in /Users/Zantana/myenv/lib/python3.8/site-packages (from tldextract->scrapy) (3.6)\n",
      "Requirement already satisfied: requests>=2.1.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from tldextract->scrapy) (2.31.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in /Users/Zantana/myenv/lib/python3.8/site-packages (from tldextract->scrapy) (2.0.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Users/Zantana/myenv/lib/python3.8/site-packages (from tldextract->scrapy) (3.13.1)\n",
      "Requirement already satisfied: six in /Users/Zantana/myenv/lib/python3.8/site-packages (from Automat>=0.8.0->Twisted<23.8.0,>=18.9.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /Users/Zantana/myenv/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Zantana/myenv/lib/python3.8/site-packages (from requests>=2.1.0->tldextract->scrapy) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/Zantana/myenv/lib/python3.8/site-packages (from requests>=2.1.0->tldextract->scrapy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Zantana/myenv/lib/python3.8/site-packages (from requests>=2.1.0->tldextract->scrapy) (2023.11.17)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapeops-scrapy-proxy-sdk in /Users/Zantana/myenv/lib/python3.8/site-packages (1.0)\n",
      "Requirement already satisfied: requests>=2.24.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapeops-scrapy-proxy-sdk) (2.31.0)\n",
      "Requirement already satisfied: scrapy>=2.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapeops-scrapy-proxy-sdk) (2.11.0)\n",
      "Requirement already satisfied: urllib3>=1.25.10 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapeops-scrapy-proxy-sdk) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Zantana/myenv/lib/python3.8/site-packages (from requests>=2.24.0->scrapeops-scrapy-proxy-sdk) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Zantana/myenv/lib/python3.8/site-packages (from requests>=2.24.0->scrapeops-scrapy-proxy-sdk) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Zantana/myenv/lib/python3.8/site-packages (from requests>=2.24.0->scrapeops-scrapy-proxy-sdk) (2023.11.17)\n",
      "Requirement already satisfied: Twisted<23.8.0,>=18.9.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (22.10.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (42.0.2)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (1.2.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (1.1.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (1.8.1)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (24.0.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (1.6.2)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (24.1.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (2.1.2)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (6.1)\n",
      "Requirement already satisfied: protego>=0.1.15 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (0.3.0)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (0.8.0)\n",
      "Requirement already satisfied: setuptools in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (49.2.1)\n",
      "Requirement already satisfied: packaging in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (23.2)\n",
      "Requirement already satisfied: tldextract in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (5.1.1)\n",
      "Requirement already satisfied: lxml>=4.4.1 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (5.1.0)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (2.0.7)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/Zantana/myenv/lib/python3.8/site-packages (from cryptography>=36.0.0->scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (1.16.0)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in /Users/Zantana/myenv/lib/python3.8/site-packages (from itemloaders>=1.0.1->scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (1.0.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from service-identity>=18.1.0->scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (23.2.0)\n",
      "Requirement already satisfied: pyasn1 in /Users/Zantana/myenv/lib/python3.8/site-packages (from service-identity>=18.1.0->scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (0.5.1)\n",
      "Requirement already satisfied: pyasn1-modules in /Users/Zantana/myenv/lib/python3.8/site-packages (from service-identity>=18.1.0->scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (0.3.0)\n",
      "Requirement already satisfied: constantly>=15.1 in /Users/Zantana/myenv/lib/python3.8/site-packages (from Twisted<23.8.0,>=18.9.0->scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (23.10.4)\n",
      "Requirement already satisfied: incremental>=21.3.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from Twisted<23.8.0,>=18.9.0->scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (22.10.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from Twisted<23.8.0,>=18.9.0->scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (22.10.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /Users/Zantana/myenv/lib/python3.8/site-packages (from Twisted<23.8.0,>=18.9.0->scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (21.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /Users/Zantana/myenv/lib/python3.8/site-packages (from Twisted<23.8.0,>=18.9.0->scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (4.9.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in /Users/Zantana/myenv/lib/python3.8/site-packages (from tldextract->scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (2.0.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Users/Zantana/myenv/lib/python3.8/site-packages (from tldextract->scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (3.13.1)\n",
      "Requirement already satisfied: six in /Users/Zantana/myenv/lib/python3.8/site-packages (from Automat>=0.8.0->Twisted<23.8.0,>=18.9.0->scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /Users/Zantana/myenv/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy>=2.0->scrapeops-scrapy-proxy-sdk) (2.21)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install scrapeops-scrapy-proxy-sdk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapeops-scrapy\n",
      "  Downloading scrapeops_scrapy-0.5.4.tar.gz (30 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tld>=0.13 (from scrapeops-scrapy)\n",
      "  Downloading tld-0.13-py2.py3-none-any.whl (263 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.8/263.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.31.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapeops-scrapy) (2.31.0)\n",
      "Collecting json5>=0.9.13 (from scrapeops-scrapy)\n",
      "  Using cached json5-0.9.14-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: urllib3>=2.1 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapeops-scrapy) (2.1.0)\n",
      "Requirement already satisfied: itemadapter>=0.8.0 in /Users/Zantana/myenv/lib/python3.8/site-packages (from scrapeops-scrapy) (0.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/Zantana/myenv/lib/python3.8/site-packages (from requests>=2.31.0->scrapeops-scrapy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/Zantana/myenv/lib/python3.8/site-packages (from requests>=2.31.0->scrapeops-scrapy) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Zantana/myenv/lib/python3.8/site-packages (from requests>=2.31.0->scrapeops-scrapy) (2023.11.17)\n",
      "Using cached json5-0.9.14-py2.py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: scrapeops-scrapy\n",
      "  Building wheel for scrapeops-scrapy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scrapeops-scrapy: filename=scrapeops_scrapy-0.5.4-py3-none-any.whl size=38280 sha256=25828b3a673e2774a4d05174c5502c33667d32ae04943c74e61d4c3c5b3a0043\n",
      "  Stored in directory: /Users/Zantana/Library/Caches/pip/wheels/fd/10/ad/bda9123aff278b3db08e7a7e4611ba01e7ab7467de4512fd3c\n",
      "Successfully built scrapeops-scrapy\n",
      "Installing collected packages: json5, tld, scrapeops-scrapy\n",
      "Successfully installed json5-0.9.14 scrapeops-scrapy-0.5.4 tld-0.13\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install scrapeops-scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/Zantana/myenv/lib/python3.8/site-packages/lxml/etree.cpython-38-darwin.so, 0x0002): symbol not found in flat namespace '_exsltDateXpathCtxtRegister'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscrapy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urljoin\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAmazonReviewsSpider\u001b[39;00m(scrapy\u001b[38;5;241m.\u001b[39mSpider):\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/scrapy/__init__.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtwisted\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version \u001b[38;5;28;01mas\u001b[39;00m _txv\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Declare top-level shortcuts\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscrapy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FormRequest, Request\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscrapy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mitem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Field, Item\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscrapy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mselector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Selector\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/scrapy/http/__init__.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscrapy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Headers\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscrapy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Request\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscrapy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FormRequest\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscrapy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson_request\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonRequest\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscrapy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrpc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XmlRpcRequest\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/scrapy/http/request/form.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterable, List, Optional, Tuple, Type, TypeVar, Union, cast\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urlencode, urljoin, urlsplit, urlunsplit\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlxml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhtml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     FormElement,\n\u001b[1;32m     13\u001b[0m     HTMLParser,\n\u001b[1;32m     14\u001b[0m     InputElement,\n\u001b[1;32m     15\u001b[0m     MultipleSelectOptions,\n\u001b[1;32m     16\u001b[0m     SelectElement,\n\u001b[1;32m     17\u001b[0m     TextareaElement,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mparsel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mselector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_root_node\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mw3lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhtml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m strip_html5_whitespace\n",
      "File \u001b[0;32m~/myenv/lib/python3.8/site-packages/lxml/html/__init__.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m urljoin\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m etree\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defs\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_setmixin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SetMixin\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/Zantana/myenv/lib/python3.8/site-packages/lxml/etree.cpython-38-darwin.so, 0x0002): symbol not found in flat namespace '_exsltDateXpathCtxtRegister'"
     ]
    }
   ],
   "source": [
    "\n",
    "import scrapy\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "class AmazonReviewsSpider(scrapy.Spider):\n",
    "    name = \"amazon_reviews\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        asin_list = ['B09G9FPHY6']\n",
    "        for asin in asin_list:\n",
    "            amazon_reviews_url = f'https://www.amazon.com/product-reviews/{asin}/'\n",
    "            yield scrapy.Request(url=amazon_reviews_url, callback=self.parse_reviews, meta={'asin': asin})\n",
    "\n",
    "    def parse_reviews(self, response):\n",
    "        asin = response.meta['asin']\n",
    "        \n",
    "        ## Parse Product Reviews\n",
    "        review_elements = response.css(\"#cm_cr-review_list div.review\")\n",
    "        for review_element in review_elements:\n",
    "            yield {\n",
    "                    \"asin\": asin,\n",
    "                    \"text\": \"\".join(review_element.css(\"span[data-hook=review-body] ::text\").getall()).strip(),\n",
    "                    \"title\": review_element.css(\"*[data-hook=review-title]>span::text\").get(),\n",
    "                    \"location_and_date\": review_element.css(\"span[data-hook=review-date] ::text\").get(),\n",
    "                    \"verified\": bool(review_element.css(\"span[data-hook=avp-badge] ::text\").get()),\n",
    "                    \"rating\": review_element.css(\"*[data-hook*=review-star-rating] ::text\").re(r\"(\\d+\\.*\\d*) out\")[0],\n",
    "                    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Using cached lxml-5.1.0-cp38-cp38-macosx_10_9_universal2.whl.metadata (3.5 kB)\n",
      "Using cached lxml-5.1.0-cp38-cp38-macosx_10_9_universal2.whl (6.2 MB)\n",
      "Installing collected packages: lxml\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 5.1.0\n",
      "    Uninstalling lxml-5.1.0:\n",
      "      Successfully uninstalled lxml-5.1.0\n",
      "Successfully installed lxml-5.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
